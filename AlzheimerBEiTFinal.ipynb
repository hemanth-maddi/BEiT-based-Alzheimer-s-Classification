{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install the Kaggle library\n",
        "!pip install kaggle\n",
        "\n",
        "# Upload the Kaggle API key\n",
        "from google.colab import files\n",
        "files.upload()  # Select the kaggle.json file downloaded from the Kaggle account settings page"
      ],
      "metadata": {
        "id": "uVWtFAbDuVBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle"
      ],
      "metadata": {
        "id": "YRSQSYtSC090"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "iylKHddTC55D"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "XcWsdqPyC779"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d sachinkumar413/alzheimer-mri-dataset"
      ],
      "metadata": {
        "id": "tmMUlORkC-vp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip alzheimer-mri-dataset.zip"
      ],
      "metadata": {
        "id": "Br1BB0DpjTaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "id": "FdBdDxmPy9oq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "vcKmsvmLy9mC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pc8hAuqVuScR"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import confusion_matrix, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoModelForImageClassification as BeitForImageClassification\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "Hj7zL9MSxxgu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWEfR-cz6fZw",
        "outputId": "6ee32a1e-65b4-4e36-f5f7-dc0ee30e6371"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alzheimer_200epoch_91.5625.pt  alzheimer-mri-dataset.zip  Dataset  kaggle.json\tsample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "full_data = torchvision.datasets.ImageFolder(root='Dataset', transform=transform)"
      ],
      "metadata": {
        "id": "M_y3F2qo6Dne"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ejy0_wqeQbZ",
        "outputId": "aac776be-efe3-450c-8c53-9f71dc1f65ca"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset ImageFolder\n",
              "    Number of datapoints: 6400\n",
              "    Root location: Dataset\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn)\n",
              "               ToTensor()\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(full_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkbwftSu0tlv",
        "outputId": "2fdfa5b5-9da9-4fd8-c564-e0a609677312"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6400"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into train, validation, and test sets\n",
        "train_data, temp_data = train_test_split(full_data, test_size=0.3)\n",
        "val_data, test_data = train_test_split(temp_data, test_size=0.5)"
      ],
      "metadata": {
        "id": "tuh98Hhfxxdg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEyefNAZfc_j",
        "outputId": "fa57f518-dfe4-429c-ce30-8db11489bfce"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "960"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data loaders\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "R9F_BqYmxxa2"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPPKFXuDhxP0",
        "outputId": "4788930c-882d-4617-823e-ac486178e858"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_data.imgs[6396:6399]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yScSsgKBgzlC",
        "outputId": "1badcfe8-d2eb-43d1-be8c-79349cfe4faf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Dataset/Very_Mild_Demented/verymild_996.jpg', 3),\n",
              " ('Dataset/Very_Mild_Demented/verymild_997.jpg', 3),\n",
              " ('Dataset/Very_Mild_Demented/verymild_998.jpg', 3)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate class weights\n",
        "class_counts = Counter(img_tuple[1] for img_tuple in full_data.imgs)\n",
        "class_weights = {cls: len(full_data) / count for cls, count in class_counts.items()}\n",
        "class_weights = [class_weights[i] for i in range(len(class_weights))]"
      ],
      "metadata": {
        "id": "h50rrJ5JxxYM"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to tensor\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float)"
      ],
      "metadata": {
        "id": "wpj00pE9xxVv"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move to GPU if available\n",
        "# if torch.cuda.is_available():\n",
        "class_weights = class_weights.to('cuda')"
      ],
      "metadata": {
        "id": "iGTULzWaxxTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "# Load the model\n",
        "model = BeitForImageClassification.from_pretrained('microsoft/beit-base-patch16-224')\n",
        "\n",
        "# Redefine the final layer to match the number of classes in your dataset\n",
        "num_classes = len(class_weights)  # Number of classes in your dataset\n",
        "model.classifier = nn.Linear(model.classifier.in_features, num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuqF99AaxxQu",
        "outputId": "8e05c29d-a31e-4d06-eba6-c9ed214f15e8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function with class weights and optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "4dVyb_CrxxOD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move the model to the GPU\n",
        "model = model.to('cuda')"
      ],
      "metadata": {
        "id": "65qtFoOveZ1P"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 200"
      ],
      "metadata": {
        "id": "ghKCrW3eoGwM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs.logits, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print('Epochs Done Till Now:', epoch+1)"
      ],
      "metadata": {
        "id": "saKkG5n4xxLg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff6e58df-1931-49c7-b082-46cb168dc33a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs Done Till Now: 1\n",
            "Epochs Done Till Now: 2\n",
            "Epochs Done Till Now: 3\n",
            "Epochs Done Till Now: 4\n",
            "Epochs Done Till Now: 5\n",
            "Epochs Done Till Now: 6\n",
            "Epochs Done Till Now: 7\n",
            "Epochs Done Till Now: 8\n",
            "Epochs Done Till Now: 9\n",
            "Epochs Done Till Now: 10\n",
            "Epochs Done Till Now: 11\n",
            "Epochs Done Till Now: 12\n",
            "Epochs Done Till Now: 13\n",
            "Epochs Done Till Now: 14\n",
            "Epochs Done Till Now: 15\n",
            "Epochs Done Till Now: 16\n",
            "Epochs Done Till Now: 17\n",
            "Epochs Done Till Now: 18\n",
            "Epochs Done Till Now: 19\n",
            "Epochs Done Till Now: 20\n",
            "Epochs Done Till Now: 21\n",
            "Epochs Done Till Now: 22\n",
            "Epochs Done Till Now: 23\n",
            "Epochs Done Till Now: 24\n",
            "Epochs Done Till Now: 25\n",
            "Epochs Done Till Now: 26\n",
            "Epochs Done Till Now: 27\n",
            "Epochs Done Till Now: 28\n",
            "Epochs Done Till Now: 29\n",
            "Epochs Done Till Now: 30\n",
            "Epochs Done Till Now: 31\n",
            "Epochs Done Till Now: 32\n",
            "Epochs Done Till Now: 33\n",
            "Epochs Done Till Now: 34\n",
            "Epochs Done Till Now: 35\n",
            "Epochs Done Till Now: 36\n",
            "Epochs Done Till Now: 37\n",
            "Epochs Done Till Now: 38\n",
            "Epochs Done Till Now: 39\n",
            "Epochs Done Till Now: 40\n",
            "Epochs Done Till Now: 41\n",
            "Epochs Done Till Now: 42\n",
            "Epochs Done Till Now: 43\n",
            "Epochs Done Till Now: 44\n",
            "Epochs Done Till Now: 45\n",
            "Epochs Done Till Now: 46\n",
            "Epochs Done Till Now: 47\n",
            "Epochs Done Till Now: 48\n",
            "Epochs Done Till Now: 49\n",
            "Epochs Done Till Now: 50\n",
            "Epochs Done Till Now: 51\n",
            "Epochs Done Till Now: 52\n",
            "Epochs Done Till Now: 53\n",
            "Epochs Done Till Now: 54\n",
            "Epochs Done Till Now: 55\n",
            "Epochs Done Till Now: 56\n",
            "Epochs Done Till Now: 57\n",
            "Epochs Done Till Now: 58\n",
            "Epochs Done Till Now: 59\n",
            "Epochs Done Till Now: 60\n",
            "Epochs Done Till Now: 61\n",
            "Epochs Done Till Now: 62\n",
            "Epochs Done Till Now: 63\n",
            "Epochs Done Till Now: 64\n",
            "Epochs Done Till Now: 65\n",
            "Epochs Done Till Now: 66\n",
            "Epochs Done Till Now: 67\n",
            "Epochs Done Till Now: 68\n",
            "Epochs Done Till Now: 69\n",
            "Epochs Done Till Now: 70\n",
            "Epochs Done Till Now: 71\n",
            "Epochs Done Till Now: 72\n",
            "Epochs Done Till Now: 73\n",
            "Epochs Done Till Now: 74\n",
            "Epochs Done Till Now: 75\n",
            "Epochs Done Till Now: 76\n",
            "Epochs Done Till Now: 77\n",
            "Epochs Done Till Now: 78\n",
            "Epochs Done Till Now: 79\n",
            "Epochs Done Till Now: 80\n",
            "Epochs Done Till Now: 81\n",
            "Epochs Done Till Now: 82\n",
            "Epochs Done Till Now: 83\n",
            "Epochs Done Till Now: 84\n",
            "Epochs Done Till Now: 85\n",
            "Epochs Done Till Now: 86\n",
            "Epochs Done Till Now: 87\n",
            "Epochs Done Till Now: 88\n",
            "Epochs Done Till Now: 89\n",
            "Epochs Done Till Now: 90\n",
            "Epochs Done Till Now: 91\n",
            "Epochs Done Till Now: 92\n",
            "Epochs Done Till Now: 93\n",
            "Epochs Done Till Now: 94\n",
            "Epochs Done Till Now: 95\n",
            "Epochs Done Till Now: 96\n",
            "Epochs Done Till Now: 97\n",
            "Epochs Done Till Now: 98\n",
            "Epochs Done Till Now: 99\n",
            "Epochs Done Till Now: 100\n",
            "Epochs Done Till Now: 101\n",
            "Epochs Done Till Now: 102\n",
            "Epochs Done Till Now: 103\n",
            "Epochs Done Till Now: 104\n",
            "Epochs Done Till Now: 105\n",
            "Epochs Done Till Now: 106\n",
            "Epochs Done Till Now: 107\n",
            "Epochs Done Till Now: 108\n",
            "Epochs Done Till Now: 109\n",
            "Epochs Done Till Now: 110\n",
            "Epochs Done Till Now: 111\n",
            "Epochs Done Till Now: 112\n",
            "Epochs Done Till Now: 113\n",
            "Epochs Done Till Now: 114\n",
            "Epochs Done Till Now: 115\n",
            "Epochs Done Till Now: 116\n",
            "Epochs Done Till Now: 117\n",
            "Epochs Done Till Now: 118\n",
            "Epochs Done Till Now: 119\n",
            "Epochs Done Till Now: 120\n",
            "Epochs Done Till Now: 121\n",
            "Epochs Done Till Now: 122\n",
            "Epochs Done Till Now: 123\n",
            "Epochs Done Till Now: 124\n",
            "Epochs Done Till Now: 125\n",
            "Epochs Done Till Now: 126\n",
            "Epochs Done Till Now: 127\n",
            "Epochs Done Till Now: 128\n",
            "Epochs Done Till Now: 129\n",
            "Epochs Done Till Now: 130\n",
            "Epochs Done Till Now: 131\n",
            "Epochs Done Till Now: 132\n",
            "Epochs Done Till Now: 133\n",
            "Epochs Done Till Now: 134\n",
            "Epochs Done Till Now: 135\n",
            "Epochs Done Till Now: 136\n",
            "Epochs Done Till Now: 137\n",
            "Epochs Done Till Now: 138\n",
            "Epochs Done Till Now: 139\n",
            "Epochs Done Till Now: 140\n",
            "Epochs Done Till Now: 141\n",
            "Epochs Done Till Now: 142\n",
            "Epochs Done Till Now: 143\n",
            "Epochs Done Till Now: 144\n",
            "Epochs Done Till Now: 145\n",
            "Epochs Done Till Now: 146\n",
            "Epochs Done Till Now: 147\n",
            "Epochs Done Till Now: 148\n",
            "Epochs Done Till Now: 149\n",
            "Epochs Done Till Now: 150\n",
            "Epochs Done Till Now: 151\n",
            "Epochs Done Till Now: 152\n",
            "Epochs Done Till Now: 153\n",
            "Epochs Done Till Now: 154\n",
            "Epochs Done Till Now: 155\n",
            "Epochs Done Till Now: 156\n",
            "Epochs Done Till Now: 157\n",
            "Epochs Done Till Now: 158\n",
            "Epochs Done Till Now: 159\n",
            "Epochs Done Till Now: 160\n",
            "Epochs Done Till Now: 161\n",
            "Epochs Done Till Now: 162\n",
            "Epochs Done Till Now: 163\n",
            "Epochs Done Till Now: 164\n",
            "Epochs Done Till Now: 165\n",
            "Epochs Done Till Now: 166\n",
            "Epochs Done Till Now: 167\n",
            "Epochs Done Till Now: 168\n",
            "Epochs Done Till Now: 169\n",
            "Epochs Done Till Now: 170\n",
            "Epochs Done Till Now: 171\n",
            "Epochs Done Till Now: 172\n",
            "Epochs Done Till Now: 173\n",
            "Epochs Done Till Now: 174\n",
            "Epochs Done Till Now: 175\n",
            "Epochs Done Till Now: 176\n",
            "Epochs Done Till Now: 177\n",
            "Epochs Done Till Now: 178\n",
            "Epochs Done Till Now: 179\n",
            "Epochs Done Till Now: 180\n",
            "Epochs Done Till Now: 181\n",
            "Epochs Done Till Now: 182\n",
            "Epochs Done Till Now: 183\n",
            "Epochs Done Till Now: 184\n",
            "Epochs Done Till Now: 185\n",
            "Epochs Done Till Now: 186\n",
            "Epochs Done Till Now: 187\n",
            "Epochs Done Till Now: 188\n",
            "Epochs Done Till Now: 189\n",
            "Epochs Done Till Now: 190\n",
            "Epochs Done Till Now: 191\n",
            "Epochs Done Till Now: 192\n",
            "Epochs Done Till Now: 193\n",
            "Epochs Done Till Now: 194\n",
            "Epochs Done Till Now: 195\n",
            "Epochs Done Till Now: 196\n",
            "Epochs Done Till Now: 197\n",
            "Epochs Done Till Now: 198\n",
            "Epochs Done Till Now: 199\n",
            "Epochs Done Till Now: 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation loop\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in val_loader:\n",
        "        images = images.to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.logits.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "print('Validation Accuracy: {} %'.format(100 * correct / total))"
      ],
      "metadata": {
        "id": "gWkqLgqoxxIx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b73b34b6-4720-4e98-8639-d35757db3f04"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 91.5625 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing loop and metrics\n",
        "model.eval()\n",
        "all_labels = []\n",
        "all_predictions = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.logits.data, 1)\n",
        "        all_labels.extend(labels)\n",
        "        all_predictions.extend(predicted)"
      ],
      "metadata": {
        "id": "UCwQovBHxxGc"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move tensors to CPU memory\n",
        "all_labels = [label.cpu() for label in all_labels]\n",
        "all_predictions = [prediction.cpu() for prediction in all_predictions]\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_predictions)\n",
        "print('Confusion Matrix:')\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "orFPo46hyW-Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbe3a42e-9abd-4c1b-b744-ba9a57ff67b4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[110   0   5   8]\n",
            " [  0  10   0   1]\n",
            " [  2   0 462  16]\n",
            " [  7   0  17 322]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LS-bJ9rl_xJD",
        "outputId": "686164e4-dbe0-4f55-b5a2-64bdbd579df9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "960"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Print the classification report\n",
        "print(classification_report(all_labels, all_predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9h2EqEK67mkt",
        "outputId": "f66c429b-36a4-4b4c-9e31-20a0e15080dc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.89      0.91       123\n",
            "           1       1.00      0.91      0.95        11\n",
            "           2       0.95      0.96      0.96       480\n",
            "           3       0.93      0.93      0.93       346\n",
            "\n",
            "    accuracy                           0.94       960\n",
            "   macro avg       0.95      0.92      0.94       960\n",
            "weighted avg       0.94      0.94      0.94       960\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'alzheimer_model.pth')"
      ],
      "metadata": {
        "id": "jwK-UkiAbdpl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}